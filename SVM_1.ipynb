{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything already extracted\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# extracted_dir = '/content/drive/MyDrive/IA/Mariposas_images'\n",
    "extracted_dir = '/home/squispeb/university/ML-Classification-p/mariposasimg'\n",
    "\n",
    "if not (os.path.exists(extracted_dir) and os.path.isdir(extracted_dir)):\n",
    "  zip_file_path = '/home/squispeb/university/ML-Classification-p/Mariposas.zip'\n",
    "  print(zip_file_path)\n",
    "  with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "      zip_ref.extractall(extracted_dir)\n",
    "  print(\"Everything extracted\")\n",
    "else:\n",
    "  print(\"Everything already extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(832, 2048)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pywt\n",
    "import pywt.data\n",
    "\n",
    "images_dir = extracted_dir + \"/images\"\n",
    "file_list = os.listdir(images_dir)\n",
    "\n",
    "newy = 64\n",
    "newx = 128\n",
    "\n",
    "new_images_path = extracted_dir + \"/images\" + str(newx) + \"x\" + str(newy)\n",
    "if not os.path.exists(new_images_path):\n",
    "  os.makedirs(new_images_path)\n",
    "\n",
    "  for filename in file_list:\n",
    "    if filename.endswith(('.jpg', '.png', '.jpeg', '.gif', '.bmp')):\n",
    "\n",
    "\n",
    "        image_path = os.path.join(images_dir, filename)\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        resized_image = image.resize((newx, newy))\n",
    "\n",
    "\n",
    "        resized_image.save( new_images_path + \"/\" + filename)\n",
    "        resized_image.close()\n",
    "        image.close()\n",
    "\n",
    "Y = []\n",
    "X = []\n",
    "for filename in file_list:\n",
    "  if filename.endswith(('.jpg', '.png', '.jpeg', '.gif', '.bmp')):\n",
    "    Y.append([int(filename[0:3])])\n",
    "    image_path = os.path.join(new_images_path, filename)\n",
    "    image = Image.open(image_path)\n",
    "    image = image.convert('L')\n",
    "    wavelet = 'haar'  # Puedes cambiar la wavelet según tus necesidades\n",
    "    coeffs = pywt.dwt2(image, wavelet)\n",
    "    approximation, (horizontal_detail, vertical_detail, diagonal_detail) = coeffs\n",
    "    vector_caracteristico = approximation.flatten()\n",
    "    X.append(vector_caracteristico)\n",
    "\n",
    "X = np.array(X)\n",
    "print(X.shape)\n",
    "Y = np.array(Y)\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "\n",
    "# Ajustar PCA a tus datos.\n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_503259/1300580971.py:49: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.lambda_list[j] -= (Y_train[j] * (Ei - Ej)) / eta\n",
      "/tmp/ipykernel_503259/1300580971.py:55: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.lambda_list[i] += Y_train[i] * Y_train[j] * (alpha_j_old - self.lambda_list[j])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [167, 665]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/squispeb/university/ML-Classification-p/SVM_1.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/SVM_1.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=111'>112</a>\u001b[0m Y_pred \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mpredict_batch(X_test)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/SVM_1.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=113'>114</a>\u001b[0m \u001b[39m# Calcular métricas de evaluación\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/SVM_1.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=114'>115</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(Y_test, Y_pred)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/SVM_1.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=115'>116</a>\u001b[0m confusion \u001b[39m=\u001b[39m confusion_matrix(Y_test, Y_pred)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/SVM_1.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=116'>117</a>\u001b[0m classification \u001b[39m=\u001b[39m classification_report(Y_test, Y_pred)\n",
      "File \u001b[0;32m~/university/ML-Classification-p/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/university/ML-Classification-p/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/university/ML-Classification-p/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/university/ML-Classification-p/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [167, 665]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class SuperVectorMachine:\n",
    "    def __init__(self, C=1.0, learning_rate=0.01, max_iter=1000, tol=1e-5):\n",
    "        self.C = C\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "    def train(self, X_train, Y_train):\n",
    "        # Normalizar los datos\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "        self.X = X_train\n",
    "        self.Y = Y_train\n",
    "        self.lambda_list = np.zeros(len(X_train))\n",
    "        self.w = np.zeros(X_train.shape[1])  # Inicializar self.w como un vector de ceros\n",
    "        self.b = 0.0\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            alpha_old = np.copy(self.lambda_list)\n",
    "            for i in range(len(X_train)):\n",
    "                Ei = self.predict(X_train[i]) - Y_train[i]\n",
    "                if (Y_train[i] * Ei < -self.tol and self.lambda_list[i] < self.C) or \\\n",
    "                   (Y_train[i] * Ei > self.tol and self.lambda_list[i] > 0):\n",
    "                    j = self.select_random_j(i, len(X_train))\n",
    "                    Ej = self.predict(X_train[j]) - Y_train[j]\n",
    "\n",
    "                    alpha_i_old = self.lambda_list[i]\n",
    "                    alpha_j_old = self.lambda_list[j]\n",
    "\n",
    "                    L, H = self.compute_L_H(self.lambda_list[j], self.lambda_list[i], Y_train[j], Y_train[i])\n",
    "\n",
    "                    if L == H:\n",
    "                        continue\n",
    "\n",
    "                    eta = 2.0 * np.dot(X_train[i], X_train[j]) - np.dot(X_train[i], X_train[i]) - np.dot(X_train[j], X_train[j])\n",
    "\n",
    "                    if eta >= 0:\n",
    "                        continue\n",
    "\n",
    "                    self.lambda_list[j] -= (Y_train[j] * (Ei - Ej)) / eta\n",
    "                    self.lambda_list[j] = self.clip_alpha(self.lambda_list[j], H, L)\n",
    "\n",
    "                    if abs(self.lambda_list[j] - alpha_j_old) < self.tol:\n",
    "                        continue\n",
    "\n",
    "                    self.lambda_list[i] += Y_train[i] * Y_train[j] * (alpha_j_old - self.lambda_list[j])\n",
    "\n",
    "                    b1 = self.b - Ei - Y_train[i] * (self.lambda_list[i] - alpha_i_old) * np.dot(X_train[i], X_train[i]) \\\n",
    "                         - Y_train[j] * (self.lambda_list[j] - alpha_j_old) * np.dot(X_train[i], X_train[j])\n",
    "                    b2 = self.b - Ej - Y_train[i] * (self.lambda_list[i] - alpha_i_old) * np.dot(X_train[i], X_train[j]) \\\n",
    "                         - Y_train[j] * (self.lambda_list[j] - alpha_j_old) * np.dot(X_train[j], X_train[j])\n",
    "\n",
    "                    if 0 < self.lambda_list[i] < self.C:\n",
    "                        self.b = b1\n",
    "                    elif 0 < self.lambda_list[j] < self.C:\n",
    "                        self.b = b2\n",
    "                    else:\n",
    "                        self.b = (b1 + b2) / 2.0\n",
    "\n",
    "            if np.all(np.abs(self.lambda_list - alpha_old) < self.tol):\n",
    "                break\n",
    "\n",
    "        # Compute the weight vector w\n",
    "        self.w = np.dot(self.lambda_list * self.Y, X_train)\n",
    "\n",
    "    def select_random_j(self, i, m):\n",
    "        j = i\n",
    "        while j == i:\n",
    "            j = np.random.randint(0, m)\n",
    "        return j\n",
    "\n",
    "    def compute_L_H(self, alpha_j, alpha_i, Y_j, Y_i):\n",
    "        if Y_i != Y_j:\n",
    "            L = max(0, alpha_j - alpha_i)\n",
    "            H = min(self.C, self.C + alpha_j - alpha_i)\n",
    "        else:\n",
    "            L = max(0, alpha_i + alpha_j - self.C)\n",
    "            H = min(self.C, alpha_i + alpha_j)\n",
    "        return L, H\n",
    "\n",
    "    def clip_alpha(self, alpha, H, L):\n",
    "        if alpha > H:\n",
    "            alpha = H\n",
    "        if alpha < L:\n",
    "            alpha = L\n",
    "        return alpha\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(self.w, x) + self.b\n",
    "\n",
    "    def predict_batch(self, X):\n",
    "        return np.sign(np.dot(self.w, X.T) + self.b)\n",
    "\n",
    "# Supongamos que tienes las siguientes variables definidas: X, Y (datos y etiquetas)\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=41)\n",
    "\n",
    "# Entrenar el modelo SVM personalizado\n",
    "svm = SuperVectorMachine(C=5.0, learning_rate=0.05, max_iter=1000, tol=1e-5)\n",
    "svm.train(X_train, Y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "Y_pred = svm.predict_batch(X_test)\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "confusion = confusion_matrix(Y_test, Y_pred)\n",
    "classification = classification_report(Y_test, Y_pred)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "classes = np.unique(Y)  # Clases únicas en tus etiquetas Y\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(confusion, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Etiqueta los valores en la matriz\n",
    "thresh = confusion.max() / 2.\n",
    "for i in range(confusion.shape[0]):\n",
    "    for j in range(confusion.shape[1]):\n",
    "        plt.text(j, i, format(confusion[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if confusion[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('Clase Real')\n",
    "plt.xlabel('Clase Predicha')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "print(\"Classification Report:\")\n",
    "print(classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
