{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY1P5GwFM9vv",
        "outputId": "3a6ccb91-5f40-41eb-f997-92b79b8dedd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLOu-R7ZPNkY",
        "outputId": "09055470-47f1-479b-dc99-10d8a91dfc64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/squispeb/university/ML-Classification-p/Mariposas.zip\n",
            "Everything extracted\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# extracted_dir = '/content/drive/MyDrive/IA/Mariposas_images'\n",
        "extracted_dir = '/home/squispeb/university/ML-Classification-p/mariposasimg'\n",
        "\n",
        "if not (os.path.exists(extracted_dir) and os.path.isdir(extracted_dir)):\n",
        "  zip_file_path = '/home/squispeb/university/ML-Classification-p/Mariposas.zip'\n",
        "  print(zip_file_path)\n",
        "  with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extracted_dir)\n",
        "  print(\"Everything extracted\")\n",
        "else:\n",
        "  print(\"Everything already extracted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTxSiQgMyo_O",
        "outputId": "d01a5758-c4f7-4736-91e9-046ffac1e86d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(832, 2048)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pywt\n",
        "import pywt.data\n",
        "\n",
        "images_dir = extracted_dir + \"/images\"\n",
        "file_list = os.listdir(images_dir)\n",
        "\n",
        "newy = 64\n",
        "newx = 128\n",
        "\n",
        "new_images_path = extracted_dir + \"/images\" + str(newx) + \"x\" + str(newy)\n",
        "if not os.path.exists(new_images_path):\n",
        "  os.makedirs(new_images_path)\n",
        "\n",
        "  for filename in file_list:\n",
        "    if filename.endswith(('.jpg', '.png', '.jpeg', '.gif', '.bmp')):\n",
        "\n",
        "\n",
        "        image_path = os.path.join(images_dir, filename)\n",
        "\n",
        "        image = Image.open(image_path)\n",
        "        resized_image = image.resize((newx, newy))\n",
        "\n",
        "\n",
        "        resized_image.save( new_images_path + \"/\" + filename)\n",
        "        resized_image.close()\n",
        "        image.close()\n",
        "\n",
        "Y = []\n",
        "X = []\n",
        "for filename in file_list:\n",
        "  if filename.endswith(('.jpg', '.png', '.jpeg', '.gif', '.bmp')):\n",
        "    Y.append([int(filename[0:3])])\n",
        "    image_path = os.path.join(new_images_path, filename)\n",
        "    image = Image.open(image_path)\n",
        "    image = image.convert('L')\n",
        "    wavelet = 'haar'  # Puedes cambiar la wavelet según tus necesidades\n",
        "    coeffs = pywt.dwt2(image, wavelet)\n",
        "    approximation, (horizontal_detail, vertical_detail, diagonal_detail) = coeffs\n",
        "    vector_caracteristico = approximation.flatten()\n",
        "    X.append(vector_caracteristico)\n",
        "\n",
        "X = np.array(X)\n",
        "print(X.shape)\n",
        "Y = np.array(Y)\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "pca = PCA(n_components=50)\n",
        "\n",
        "# Ajustar PCA a tus datos.\n",
        "X = pca.fit_transform(X)\n",
        "\n",
        "# 'X_transformed' contiene los datos transformados con PCA y reducidos a 'n_components' dimensiones.\n",
        "\n",
        "# Si deseas saber cuánta varianza explican tus componentes principales, puedes acceder a la información de varianza.\n",
        "#explained_variance = pca.explained_variance_ratio_\n",
        "# print(\"Varianza explicada por cada componente:\", explained_variance)\n",
        "#print(X.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (832, 50)\n",
            "Y shape: (832,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert X and Y to numpy arrays\n",
        "# X = np.array(X)\n",
        "# Y = np.array(Y)\n",
        "\n",
        "# Print the shapes of X and Y\n",
        "\n",
        "\n",
        "\n",
        "dataset = np.concatenate((X, Y.reshape(-1, 1)), axis=1)\n",
        "# Print the first 5 rows of X and Y\n",
        "X, Y = dataset[:,:-1], dataset[:,-1]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"Y shape:\", Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2K72R92hQrpz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, random_state=41)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uQgEiSI4nn4s"
      },
      "outputs": [],
      "source": [
        "class Node():\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "        self.value = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dSQFEY0inwOc"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "\n",
        "class DT():\n",
        "    def __init__(self):\n",
        "        self.root = None\n",
        "\n",
        "    def build_tree(self, dataset):\n",
        "\n",
        "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
        "        num_samples, num_features = np.shape(X)\n",
        "\n",
        "        if not self.IsTerminal(Y):\n",
        "            best_split = self.BestSplit(dataset, num_samples, num_features)\n",
        "\n",
        "            left_subtree = self.build_tree(best_split[\"dataset_left\"])\n",
        "            right_subtree = self.build_tree(best_split[\"dataset_right\"])\n",
        "            return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
        "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
        "\n",
        "        leaf_value = Y[0]\n",
        "        return Node(value=leaf_value, info_gain=0)\n",
        "\n",
        "    def IsTerminal(self, Y):\n",
        "      return np.all(Y == Y[0])\n",
        "\n",
        "    def BestSplit(self, dataset, num_samples, num_features):\n",
        "\n",
        "        best_split = {}\n",
        "        max_info_gain = -float(\"inf\")\n",
        "\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "            possible_thresholds = np.unique(feature_values)\n",
        "            threshold = np.median(possible_thresholds)\n",
        "            dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "            if len(dataset_left)>0 and len(dataset_right)>0:\n",
        "                y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "                curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
        "                if curr_info_gain>max_info_gain:\n",
        "                    best_split[\"feature_index\"] = feature_index\n",
        "                    best_split[\"threshold\"] = threshold\n",
        "                    best_split[\"dataset_left\"] = dataset_left\n",
        "                    best_split[\"dataset_right\"] = dataset_right\n",
        "                    best_split[\"info_gain\"] = curr_info_gain\n",
        "                    max_info_gain = curr_info_gain\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def split(self, dataset, feature_index, threshold):\n",
        "\n",
        "      sorted_dataset = dataset[np.argsort(dataset[:, feature_index])]\n",
        "      split_index = np.searchsorted(sorted_dataset[:, feature_index], threshold)\n",
        "\n",
        "      dataset_left = sorted_dataset[:split_index]\n",
        "      dataset_right = sorted_dataset[split_index:]\n",
        "      return dataset_left, dataset_right\n",
        "\n",
        "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
        "\n",
        "        weight_l = len(l_child) / len(parent)\n",
        "        weight_r = len(r_child) / len(parent)\n",
        "        if mode==\"gini\":\n",
        "            gain = self.Gini(parent) - (weight_l*self.Gini(l_child) + weight_r*self.Gini(r_child))\n",
        "        else:\n",
        "            gain = self.Entropy(parent) - (weight_l*self.Entropy(l_child) + weight_r*self.Entropy(r_child))\n",
        "        return gain\n",
        "\n",
        "    def Entropy(self, y):\n",
        "\n",
        "      class_labels = np.unique(y)\n",
        "      entropy = 0\n",
        "      for cls in class_labels:\n",
        "        p_cls = len(y[y == cls]) / len(y)\n",
        "        entropy += -p_cls * np.log2(p_cls)\n",
        "      return entropy\n",
        "\n",
        "    def Gini(self, y):\n",
        "\n",
        "        class_labels = np.unique(y)\n",
        "        gini = 0\n",
        "        for cls in class_labels:\n",
        "            p_cls = len(y[y == cls]) / len(y)\n",
        "            gini += p_cls**2\n",
        "        return 1 - gini\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "\n",
        "        dataset = np.concatenate((X, Y), axis=1)\n",
        "        self.root = self.build_tree(dataset)\n",
        "\n",
        "    def predict(self, x):\n",
        "\n",
        "        predition = self.make_prediction(x, self.root)\n",
        "        return predition\n",
        "\n",
        "    def make_prediction(self, x, tree):\n",
        "\n",
        "        if tree.value!=None:\n",
        "          return tree.value\n",
        "        feature_val = x[tree.feature_index]\n",
        "        if feature_val<=tree.threshold:\n",
        "            return self.make_prediction(x, tree.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, tree.right)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class LinearRegression():\n",
        "    def __init__(self):\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "        self.L = None\n",
        "\n",
        "    def h(self, x):\n",
        "        \"\"\"\n",
        "        x: vector de caracteristicas\n",
        "        \"\"\"\n",
        "        return np.dot(x, self.w)\n",
        "\n",
        "    def LossFunction(self, x, y):\n",
        "        \"\"\"\n",
        "        X: vector de caracteristicas\n",
        "        Y: vector de etiquetas\n",
        "        \"\"\"\n",
        "        n = len(x)\n",
        "        loss = np.sum((self.h(x) - y) ** 2) / (2 * n)\n",
        "        return loss\n",
        "\n",
        "    def Derivatives(self, x, y):\n",
        "        \"\"\"\n",
        "        x: vector de caracteristicas\n",
        "        y: vector de etiquetas\n",
        "        \"\"\"\n",
        "        n = len(x)\n",
        "        dw = np.dot(x.T, (self.h(x) - y)) / n\n",
        "        db = np.sum(self.h(x) - y) / n\n",
        "        return dw, db\n",
        "\n",
        "    def ChangeParameters(self, x, y, alpha):\n",
        "        \"\"\"\n",
        "        x: vector de caracteristicas\n",
        "        y: vector de etiquetas\n",
        "        learning_rate: tasa de aprendizaje\n",
        "        \"\"\"\n",
        "        dw, db = self.Derivatives(x, y)\n",
        "        self.w -= alpha * dw\n",
        "        self.b -= alpha * db\n",
        "\n",
        "    def Training(self, x, y, epochs=100, alpha=0.01):\n",
        "        \"\"\"\n",
        "        x: vector de caracteristicas\n",
        "        y: vector de etiquetas\n",
        "        epochs: numero de iteraciones\n",
        "        \"\"\"\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3, random_state=41)\n",
        "        self.w = np.random.random(x.shape[1])\n",
        "        self.b = 0\n",
        "        for i in range(epochs):\n",
        "            self.L = self.LossFunction(x_train, y_train)\n",
        "            dw, db = self.Derivatives(x_train, y_train)\n",
        "            self.w -= alpha * dw\n",
        "            self.b -= alpha * db\n",
        "        test_loss = self.LossFunction(x_test, y_test)\n",
        "        return self.L, test_loss\n",
        "\n",
        "    def Testing(self, x):\n",
        "        \"\"\"\n",
        "        x: vector de caracteristicas\n",
        "        \"\"\"\n",
        "        y_pred = self.h(x)\n",
        "        return y_pred\n",
        "\n",
        "    def Graph(self, x, y):\n",
        "        \"\"\"\n",
        "        x: vector de caracteristicas\n",
        "        y: vector de etiquetas\n",
        "        \"\"\"\n",
        "        plt.scatter(x, y)\n",
        "        plt.plot(x, self.h(x), color='red')\n",
        "        plt.show()\n",
        "\n",
        "       \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -1.5919e+02 -3.2114e+02  3e+03  5e+01  2e+00\n",
            " 1: -2.3735e+02 -2.5911e+02  2e+03  3e+01  1e+00\n",
            " 2: -3.1015e+02 -1.4297e+02  8e+02  1e+01  5e-01\n",
            " 3: -1.0283e+02 -1.1741e+01  2e+02  3e+00  1e-01\n",
            " 4: -3.1164e+00 -8.2154e-03  9e+00  1e-01  6e-03\n",
            " 5: -3.1359e-02 -2.7861e-06  9e-02  1e-03  2e-04\n",
            " 6: -3.1360e-04 -5.3243e-10  9e-04  1e-05  2e-06\n",
            " 7: -3.1381e-06 -1.0167e-10  9e-06  1e-07  3e-08\n",
            " 8: -3.3432e-08 -1.0159e-10  9e-08  1e-09  4e-10\n",
            "Optimal solution found.\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -1.5919e+02 -3.2114e+02  3e+03  5e+01  2e+00\n",
            " 1: -2.3735e+02 -2.5911e+02  2e+03  3e+01  1e+00\n",
            " 2: -3.1015e+02 -1.4297e+02  8e+02  1e+01  5e-01\n",
            " 3: -1.0283e+02 -1.1741e+01  2e+02  3e+00  1e-01\n",
            " 4: -3.1164e+00 -8.2154e-03  9e+00  1e-01  6e-03\n",
            " 5: -3.1359e-02 -2.7861e-06  9e-02  1e-03  2e-04\n",
            " 6: -3.1360e-04 -5.3243e-10  9e-04  1e-05  2e-06\n",
            " 7: -3.1381e-06 -1.0167e-10  9e-06  1e-07  3e-08\n",
            " 8: -3.3432e-08 -1.0159e-10  9e-08  1e-09  4e-10\n",
            "Optimal solution found.\n"
          ]
        }
      ],
      "source": [
        "from cvxopt import matrix, solvers\n",
        "\n",
        "\n",
        "class SuperVectorMachine:\n",
        "    def __init__(self):\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "        self.lambda_list = None\n",
        "        self.X = None\n",
        "        self.Y = None\n",
        "\n",
        "    def GetLambda(self):\n",
        "        X = self.X  # Asegúrate de que X y Y estén definidos en tu instancia\n",
        "        Y = self.Y\n",
        "\n",
        "        K = np.dot(X, X.T) * np.dot(Y, Y.T)\n",
        "        P = matrix(K)\n",
        "        q = matrix(-np.ones((len(X), 1)))\n",
        "        G = matrix(-np.eye(len(X)))\n",
        "        h = matrix(np.zeros(len(X)))\n",
        "\n",
        "        # A debe ser una matriz con una fila y el número correcto de columnas\n",
        "        A = matrix(Y, (1, len(Y)), tc='d')  # Esto asume que Y es un array bidimensional\n",
        "        b = matrix(np.zeros(1))\n",
        "\n",
        "        sol = solvers.qp(P, q, G, h, A, b)\n",
        "        alpha = np.array(sol[\"x\"])\n",
        "        return alpha\n",
        "    \n",
        "    def GetLambdaList(self):\n",
        "        list = self.GetLambda()\n",
        "        self.lambda_list = list > 1e-10\n",
        "        return self.lambda_list\n",
        "\n",
        "    def GetW(self, X, Y):\n",
        "        self.lambda_list = self.GetLambdaList()\n",
        "        W = []\n",
        "        for j in range(X.shape[1]):\n",
        "            W.append(sum([self.lambda_list[i] * Y[i] * X[i][j] for i in range(len(self.Y))]))\n",
        "        self.w = W\n",
        "        return self.w\n",
        "\n",
        "    def GetB(self, X, W):\n",
        "        X = np.array(X)\n",
        "        W = np.array(W)\n",
        "        W_t = W.reshape(-1, 1)\n",
        "        self.b = -np.mean(np.dot(X, W_t))\n",
        "        return self.b\n",
        "\n",
        "    def Predict(self, X, W, b):\n",
        "        Y = []\n",
        "        W = np.squeeze(W)\n",
        "        for i in range(X.shape[0]):\n",
        "            X[i] = X[i].reshape(1, -1)\n",
        "            if np.dot(W, X[i]) + b >= 0:\n",
        "                Y.append(1)\n",
        "            else:\n",
        "                Y.append(-1)\n",
        "        return np.array(Y)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Test the SuperVectorMachine class\n",
        "svm = SuperVectorMachine()\n",
        "svm.X = X\n",
        "svm.Y = Y\n",
        "svm.GetLambda()\n",
        "W = svm.GetW(X, Y)\n",
        "b = svm.GetB(X_train, W)\n",
        "\n",
        "Y = svm.Predict(X, W, b)\n",
        "\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3)\n",
        "\n",
        "# Y_pred = svm.Predict(X_test, W, b)\n",
        "\n",
        "# confussion_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1  1 -1  1  1  1  1  1 -1  1  1  1 -1  1  1  1  1 -1 -1 -1 -1  1  1 -1\n",
            " -1  1  1 -1  1 -1 -1 -1 -1  1 -1 -1 -1  1 -1  1  1  1  1  1  1  1 -1  1\n",
            "  1 -1 -1  1  1 -1  1  1 -1  1  1  1  1 -1 -1  1 -1 -1 -1  1  1 -1  1 -1\n",
            " -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1  1 -1  1 -1 -1  1  1  1 -1  1  1  1\n",
            "  1  1  1 -1  1 -1  1  1  1  1  1  1 -1  1  1  1 -1  1 -1  1 -1  1 -1  1\n",
            "  1  1  1  1 -1 -1 -1 -1 -1  1 -1  1 -1  1 -1 -1 -1  1 -1 -1 -1  1 -1  1\n",
            "  1  1 -1 -1 -1 -1  1  1 -1 -1 -1  1  1  1  1  1  1  1 -1 -1 -1  1 -1 -1\n",
            " -1  1 -1 -1 -1  1  1 -1 -1  1 -1 -1  1  1 -1  1 -1 -1 -1 -1 -1 -1  1  1\n",
            "  1 -1  1  1  1  1 -1  1 -1  1 -1  1  1 -1  1  1  1 -1 -1 -1  1  1  1 -1\n",
            " -1  1  1 -1 -1 -1  1 -1  1  1  1  1 -1  1 -1  1 -1  1  1 -1  1 -1  1 -1\n",
            "  1  1 -1  1  1  1  1 -1 -1 -1 -1 -1  1  1  1 -1 -1  1  1 -1  1 -1  1  1\n",
            "  1  1  1 -1  1  1  1  1 -1 -1  1  1  1 -1 -1  1  1 -1 -1  1  1  1  1 -1\n",
            " -1  1 -1 -1  1 -1  1  1 -1  1  1 -1 -1 -1 -1 -1 -1  1  1  1  1 -1  1  1\n",
            " -1  1 -1 -1  1  1 -1 -1 -1 -1  1 -1  1 -1  1 -1 -1  1 -1  1 -1  1 -1 -1\n",
            "  1 -1  1  1 -1  1 -1  1  1  1 -1  1 -1  1 -1  1 -1  1 -1 -1 -1 -1  1 -1\n",
            " -1 -1  1 -1  1  1  1  1 -1 -1  1 -1  1  1  1 -1  1 -1  1 -1 -1 -1 -1  1\n",
            " -1 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1  1 -1  1  1  1 -1  1 -1 -1 -1 -1\n",
            " -1  1 -1  1 -1  1  1 -1  1 -1 -1  1 -1  1  1  1  1 -1  1 -1 -1  1 -1  1\n",
            " -1 -1  1  1  1  1  1 -1  1 -1 -1  1  1  1 -1 -1  1 -1 -1 -1  1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1  1  1 -1  1 -1  1 -1  1  1 -1 -1 -1 -1 -1 -1  1  1  1 -1\n",
            " -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1  1 -1  1  1  1 -1  1  1 -1  1  1 -1 -1\n",
            " -1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1 -1  1  1 -1 -1  1  1  1  1  1 -1\n",
            "  1 -1 -1  1  1  1  1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1  1 -1 -1 -1  1 -1\n",
            "  1  1  1  1  1 -1  1  1 -1  1  1  1 -1 -1  1 -1 -1  1 -1 -1 -1  1 -1  1\n",
            "  1 -1 -1 -1  1  1 -1 -1  1 -1 -1 -1  1 -1  1 -1  1  1 -1  1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1  1  1 -1 -1  1 -1 -1  1  1  1 -1 -1  1  1 -1 -1  1  1  1  1\n",
            "  1 -1  1 -1  1 -1  1 -1  1  1  1 -1 -1 -1  1 -1  1 -1 -1  1  1 -1  1 -1\n",
            " -1 -1 -1  1  1  1  1 -1  1 -1  1  1  1  1 -1  1  1  1  1  1 -1  1 -1 -1\n",
            " -1 -1 -1 -1  1 -1 -1  1 -1 -1  1 -1  1 -1 -1 -1  1 -1  1  1 -1  1 -1 -1\n",
            "  1  1 -1 -1  1 -1  1  1  1  1 -1  1  1 -1  1 -1  1 -1  1 -1  1  1  1 -1\n",
            "  1  1  1  1  1 -1 -1  1 -1 -1  1 -1  1  1 -1 -1 -1  1  1  1 -1 -1  1 -1\n",
            " -1 -1  1  1  1  1 -1  1 -1  1  1  1 -1 -1  1 -1 -1  1  1 -1 -1  1 -1  1\n",
            "  1  1 -1  1 -1 -1  1  1 -1  1  1 -1 -1 -1 -1 -1 -1  1  1 -1  1  1 -1 -1\n",
            "  1 -1  1 -1 -1 -1  1  1  1  1  1 -1  1  1  1  1  1 -1  1 -1 -1  1  1  1\n",
            "  1  1  1 -1  1  1 -1  1 -1 -1 -1  1  1  1 -1 -1]\n"
          ]
        }
      ],
      "source": [
        "print(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Crea la figura y los ejes\n",
        "\n",
        "# classes = [-1, 1]  # Clases negativa y positiva\n",
        "\n",
        "# plt.figure()\n",
        "# plt.imshow(confussion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "# plt.title(\"Matriz de Confusión\")\n",
        "# plt.colorbar()\n",
        "# tick_marks = np.arange(len(classes))\n",
        "# plt.xticks(tick_marks, classes, rotation=45)\n",
        "# plt.yticks(tick_marks, classes)\n",
        "\n",
        "# # Etiqueta los valores en la matriz\n",
        "# thresh = confussion_matrix.max() / 2.\n",
        "# for i in range(confussion_matrix.shape[0]):\n",
        "#     for j in range(confussion_matrix.shape[1]):\n",
        "#         plt.text(j, i, format(confussion_matrix[i, j], 'd'),\n",
        "#                  horizontalalignment=\"center\",\n",
        "#                  color=\"white\" if confussion_matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "# plt.ylabel('Clase Real')\n",
        "# plt.xlabel('Clase Predicha')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# print(y_pred)\n",
        "# print(Y_test)\n",
        "# print(accuracy_score(Y_test, y_pred))\n",
        "# print(confusion_matrix(Y_test, y_pred))\n",
        "# print(classification_report(Y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    # def train(self,x,y, epochs):\n",
        "    #     num_samples, num_caracteristicas = x.shape\n",
        "    #     self.numero_clases = len(np.unique(y))  \n",
        "    #     self.w = np.zeros((self.numero_clases, num_caracteristicas))\n",
        "\n",
        "    #     for i in range(epochs):\n",
        "    #        for c in range(self.numero_clases):\n",
        "    #           y_class = (y == c).astype(int)\n",
        "\n",
        "    #           s=self.S(x,self.w[c])\n",
        "    #           loss=s-y_class\n",
        "    #           gradient = np.dot(x.T, loss) / num_samples\n",
        "    #           self.w[c] -= self.alpha * gradient\n",
        "\n",
        "    # def predict(self,x):\n",
        "    #     num_samples= x.shape[0]\n",
        "    #     y_pred = np.zeros(num_samples, dtype=int)\n",
        "    #     for i in range(num_samples):\n",
        "    #          class_probs = [self.S(x[i], self.w[c]) for c in range(self.numero_clases)]\n",
        "    #          y_pred[i] = np.argmax(class_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (831,) (831,582) (831,) ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/squispeb/university/ML-Classification-p/Loader(2).ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m LinearRegression()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Fit the model to the data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39;49mTraining(X, Y)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mTesting(X)\n",
            "\u001b[1;32m/home/squispeb/university/ML-Classification-p/Loader(2).ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLossFunction(x_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m     dw, db \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDerivatives(x_train, y_train)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw \u001b[39m-\u001b[39;49m\u001b[39m=\u001b[39;49m alpha \u001b[39m*\u001b[39;49m dw\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m alpha \u001b[39m*\u001b[39m db\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m test_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLossFunction(x_test, y_test)\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (831,) (831,582) (831,) "
          ]
        }
      ],
      "source": [
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "model.Training(X, Y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.Testing(X)\n",
        "\n",
        "# Graph the model\n",
        "model.Graph(X, Y)\n",
        "\n",
        "# # Create a linear regression model\n",
        "# model = LinearRegression()\n",
        "\n",
        "# # Fit the model to the data\n",
        "# model.fit(X, Y)\n",
        "\n",
        "# # Make predictions\n",
        "# y_pred = model.predict(X)\n",
        "\n",
        "# # Graph the model\n",
        "# model.Graph(X, Y)\n",
        "\n",
        "\n",
        "# print(X.shape)\n",
        "# print(len(np.unique(Y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D0rpdjtWA5C4"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.utils import resample\n",
        "def selectRandomReplace(X, Y, numberOfRegisters):\n",
        "\n",
        "  bootstrap_X, bootstrap_Y = resample(X, Y, n_samples=numberOfRegisters, replace=True, random_state=None)  # Set random_state for reproducibility\n",
        "\n",
        "  return bootstrap_X, bootstrap_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fpF_yPShAEib"
      },
      "outputs": [],
      "source": [
        "def makeRandomForest(X, Y, numberOfTrees, numberOfRegisters=10):\n",
        "  T = []\n",
        "  for i in range(numberOfTrees):\n",
        "    xi_train, yi_train = selectRandomReplace(X, Y, numberOfRegisters)\n",
        "    T.append(DT())\n",
        "    T[i].fit(xi_train, yi_train)\n",
        "  return T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ick9hf5kCgv-"
      },
      "outputs": [],
      "source": [
        "Forest = makeRandomForest(X, Y, 10, 832)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HkIl75rRgB7c"
      },
      "outputs": [],
      "source": [
        "def forestPredict(x, forest):\n",
        "  classes = [t.predict(x) for t in forest]\n",
        "  unique_elements, element_counts = np.unique(classes, return_counts=True)\n",
        "  index_of_most_common = np.argmax(element_counts)\n",
        "  return unique_elements[index_of_most_common]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u0YFkrpWhWjs"
      },
      "outputs": [],
      "source": [
        "def forestPredictions(X, forest):\n",
        "  predictions = []\n",
        "  for x in X:\n",
        "    predictions.append([forestPredict(x, forest)])\n",
        "\n",
        "  return np.array(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vMhjKSiiBcF",
        "outputId": "0721ed23-464e-4274-9f92-0cca9a1ab36b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ]
        }
      ],
      "source": [
        "y_comita = forestPredictions(X_test, Forest)\n",
        "\n",
        "print(y_comita == Y_test)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
