{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY1P5GwFM9vv",
        "outputId": "3a6ccb91-5f40-41eb-f997-92b79b8dedd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLOu-R7ZPNkY",
        "outputId": "09055470-47f1-479b-dc99-10d8a91dfc64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/squispeb/university/ML-Classification-p/Mariposas.zip\n",
            "Everything extracted\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# extracted_dir = '/content/drive/MyDrive/IA/Mariposas_images'\n",
        "extracted_dir = '/home/squispeb/university/ML-Classification-p/mariposasimg'\n",
        "\n",
        "if not (os.path.exists(extracted_dir) and os.path.isdir(extracted_dir)):\n",
        "  zip_file_path = '/home/squispeb/university/ML-Classification-p/Mariposas.zip'\n",
        "  print(zip_file_path)\n",
        "  with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extracted_dir)\n",
        "  print(\"Everything extracted\")\n",
        "else:\n",
        "  print(\"Everything already extracted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTxSiQgMyo_O",
        "outputId": "d01a5758-c4f7-4736-91e9-046ffac1e86d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(832, 2048)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pywt\n",
        "import pywt.data\n",
        "\n",
        "images_dir = extracted_dir + \"/images\"\n",
        "file_list = os.listdir(images_dir)\n",
        "\n",
        "newy = 64\n",
        "newx = 128\n",
        "\n",
        "new_images_path = extracted_dir + \"/images\" + str(newx) + \"x\" + str(newy)\n",
        "if not os.path.exists(new_images_path):\n",
        "  os.makedirs(new_images_path)\n",
        "\n",
        "  for filename in file_list:\n",
        "    if filename.endswith(('.jpg', '.png', '.jpeg', '.gif', '.bmp')):\n",
        "\n",
        "\n",
        "        image_path = os.path.join(images_dir, filename)\n",
        "\n",
        "        image = Image.open(image_path)\n",
        "        resized_image = image.resize((newx, newy))\n",
        "\n",
        "\n",
        "        resized_image.save( new_images_path + \"/\" + filename)\n",
        "        resized_image.close()\n",
        "        image.close()\n",
        "\n",
        "Y = []\n",
        "X = []\n",
        "for filename in file_list:\n",
        "  if filename.endswith(('.jpg', '.png', '.jpeg', '.gif', '.bmp')):\n",
        "    Y.append([int(filename[0:3])])\n",
        "    image_path = os.path.join(new_images_path, filename)\n",
        "    image = Image.open(image_path)\n",
        "    image = image.convert('L')\n",
        "    wavelet = 'haar'  # Puedes cambiar la wavelet según tus necesidades\n",
        "    coeffs = pywt.dwt2(image, wavelet)\n",
        "    approximation, (horizontal_detail, vertical_detail, diagonal_detail) = coeffs\n",
        "    vector_caracteristico = approximation.flatten()\n",
        "    X.append(vector_caracteristico)\n",
        "\n",
        "X = np.array(X)\n",
        "print(X.shape)\n",
        "Y = np.array(Y)\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "pca = PCA(n_components=50)\n",
        "\n",
        "# Ajustar PCA a tus datos.\n",
        "X = pca.fit_transform(X)\n",
        "\n",
        "# 'X_transformed' contiene los datos transformados con PCA y reducidos a 'n_components' dimensiones.\n",
        "\n",
        "# Si deseas saber cuánta varianza explican tus componentes principales, puedes acceder a la información de varianza.\n",
        "#explained_variance = pca.explained_variance_ratio_\n",
        "# print(\"Varianza explicada por cada componente:\", explained_variance)\n",
        "#print(X.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (832, 50)\n",
            "Y shape: (832,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert X and Y to numpy arrays\n",
        "# X = np.array(X)\n",
        "# Y = np.array(Y)\n",
        "\n",
        "# Print the shapes of X and Y\n",
        "\n",
        "\n",
        "\n",
        "dataset = np.concatenate((X, Y.reshape(-1, 1)), axis=1)\n",
        "# Print the first 5 rows of X and Y\n",
        "X, Y = dataset[:,:-1], dataset[:,-1]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"Y shape:\", Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2K72R92hQrpz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, random_state=41)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uQgEiSI4nn4s"
      },
      "outputs": [],
      "source": [
        "class Node():\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "        self.value = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dSQFEY0inwOc"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "\n",
        "class DT():\n",
        "    def __init__(self):\n",
        "        self.root = None\n",
        "\n",
        "    def build_tree(self, dataset):\n",
        "\n",
        "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
        "        num_samples, num_features = np.shape(X)\n",
        "\n",
        "        if not self.IsTerminal(Y):\n",
        "            best_split = self.BestSplit(dataset, num_samples, num_features)\n",
        "\n",
        "            left_subtree = self.build_tree(best_split[\"dataset_left\"])\n",
        "            right_subtree = self.build_tree(best_split[\"dataset_right\"])\n",
        "            return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
        "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
        "\n",
        "        leaf_value = Y[0]\n",
        "        return Node(value=leaf_value, info_gain=0)\n",
        "\n",
        "    def IsTerminal(self, Y):\n",
        "      return np.all(Y == Y[0])\n",
        "\n",
        "    def BestSplit(self, dataset, num_samples, num_features):\n",
        "\n",
        "        best_split = {}\n",
        "        max_info_gain = -float(\"inf\")\n",
        "\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "            possible_thresholds = np.unique(feature_values)\n",
        "            threshold = np.median(possible_thresholds)\n",
        "            dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "            if len(dataset_left)>0 and len(dataset_right)>0:\n",
        "                y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "                curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
        "                if curr_info_gain>max_info_gain:\n",
        "                    best_split[\"feature_index\"] = feature_index\n",
        "                    best_split[\"threshold\"] = threshold\n",
        "                    best_split[\"dataset_left\"] = dataset_left\n",
        "                    best_split[\"dataset_right\"] = dataset_right\n",
        "                    best_split[\"info_gain\"] = curr_info_gain\n",
        "                    max_info_gain = curr_info_gain\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def split(self, dataset, feature_index, threshold):\n",
        "\n",
        "      sorted_dataset = dataset[np.argsort(dataset[:, feature_index])]\n",
        "      split_index = np.searchsorted(sorted_dataset[:, feature_index], threshold)\n",
        "\n",
        "      dataset_left = sorted_dataset[:split_index]\n",
        "      dataset_right = sorted_dataset[split_index:]\n",
        "      return dataset_left, dataset_right\n",
        "\n",
        "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
        "\n",
        "        weight_l = len(l_child) / len(parent)\n",
        "        weight_r = len(r_child) / len(parent)\n",
        "        if mode==\"gini\":\n",
        "            gain = self.Gini(parent) - (weight_l*self.Gini(l_child) + weight_r*self.Gini(r_child))\n",
        "        else:\n",
        "            gain = self.Entropy(parent) - (weight_l*self.Entropy(l_child) + weight_r*self.Entropy(r_child))\n",
        "        return gain\n",
        "\n",
        "    def Entropy(self, y):\n",
        "\n",
        "      class_labels = np.unique(y)\n",
        "      entropy = 0\n",
        "      for cls in class_labels:\n",
        "        p_cls = len(y[y == cls]) / len(y)\n",
        "        entropy += -p_cls * np.log2(p_cls)\n",
        "      return entropy\n",
        "\n",
        "    def Gini(self, y):\n",
        "\n",
        "        class_labels = np.unique(y)\n",
        "        gini = 0\n",
        "        for cls in class_labels:\n",
        "            p_cls = len(y[y == cls]) / len(y)\n",
        "            gini += p_cls**2\n",
        "        return 1 - gini\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "\n",
        "        dataset = np.concatenate((X, Y), axis=1)\n",
        "        self.root = self.build_tree(dataset)\n",
        "\n",
        "    def predict(self, x):\n",
        "\n",
        "        predition = self.make_prediction(x, self.root)\n",
        "        return predition\n",
        "\n",
        "    def make_prediction(self, x, tree):\n",
        "\n",
        "        if tree.value!=None:\n",
        "          return tree.value\n",
        "        feature_val = x[tree.feature_index]\n",
        "        if feature_val<=tree.threshold:\n",
        "            return self.make_prediction(x, tree.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, tree.right)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class LinearRegression():\n",
        "    def __init__(self):\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "        self.L = None\n",
        "\n",
        "    def h(self, x):\n",
        "        \"\"\"\n",
        "        x: vector de caracteristicas\n",
        "        \"\"\"\n",
        "        return np.dot(x, self.w)\n",
        "\n",
        "    def LossFunction(self, x, y):\n",
        "        \"\"\"\n",
        "        X: vector de caracteristicas\n",
        "        Y: vector de etiquetas\n",
        "        \"\"\"\n",
        "        n = len(x)\n",
        "        loss = np.sum((self.h(x) - y) ** 2) / (2 * n)\n",
        "        return loss\n",
        "\n",
        "    def Derivatives(self, x, y):\n",
        "        \"\"\"\n",
        "        x: vector de caracteristicas\n",
        "        y: vector de etiquetas\n",
        "        \"\"\"\n",
        "        n = len(x)\n",
        "        dw = np.dot(x.T, (self.h(x) - y)) / n\n",
        "        db = np.sum(self.h(x) - y) / n\n",
        "        return dw, db\n",
        "\n",
        "    def ChangeParameters(self, x, y, alpha):\n",
        "        \"\"\"\n",
        "        x: vector de caracteristicas\n",
        "        y: vector de etiquetas\n",
        "        learning_rate: tasa de aprendizaje\n",
        "        \"\"\"\n",
        "        dw, db = self.Derivatives(x, y)\n",
        "        self.w -= alpha * dw\n",
        "        self.b -= alpha * db\n",
        "\n",
        "    def Training(self, x, y, epochs=100, alpha=0.01):\n",
        "        \"\"\"\n",
        "        x: vector de caracteristicas\n",
        "        y: vector de etiquetas\n",
        "        epochs: numero de iteraciones\n",
        "        \"\"\"\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3, random_state=41)\n",
        "        self.w = np.random.random(x.shape[1])\n",
        "        self.b = 0\n",
        "        for i in range(epochs):\n",
        "            self.L = self.LossFunction(x_train, y_train)\n",
        "            dw, db = self.Derivatives(x_train, y_train)\n",
        "            self.w -= alpha * dw\n",
        "            self.b -= alpha * db\n",
        "        test_loss = self.LossFunction(x_test, y_test)\n",
        "        return self.L, test_loss\n",
        "\n",
        "    def Testing(self, x):\n",
        "        \"\"\"\n",
        "        x: vector de caracteristicas\n",
        "        \"\"\"\n",
        "        y_pred = self.h(x)\n",
        "        return y_pred\n",
        "\n",
        "    def Graph(self, x, y):\n",
        "        \"\"\"\n",
        "        x: vector de caracteristicas\n",
        "        y: vector de etiquetas\n",
        "        \"\"\"\n",
        "        plt.scatter(x, y)\n",
        "        plt.plot(x, self.h(x), color='red')\n",
        "        plt.show()\n",
        "\n",
        "       \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -8.3053e+02 -1.8015e+03  1e+03  5e-14  2e+00\n",
            " 1: -1.9119e+03 -1.9363e+03  2e+01  2e-13  1e+00\n",
            " 2: -1.1557e+04 -1.1692e+04  1e+02  1e-12  1e+00\n",
            "Terminated (singular KKT matrix).\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -8.3053e+02 -1.8015e+03  1e+03  5e-14  2e+00\n",
            " 1: -1.9119e+03 -1.9363e+03  2e+01  2e-13  1e+00\n",
            " 2: -1.1557e+04 -1.1692e+04  1e+02  1e-12  1e+00\n",
            "Terminated (singular KKT matrix).\n"
          ]
        }
      ],
      "source": [
        "from cvxopt import matrix, solvers\n",
        "\n",
        "\n",
        "class SuperVectorMachine:\n",
        "    def __init__(self):\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "        self.lambda_list = None\n",
        "        self.X = None\n",
        "        self.Y = None\n",
        "\n",
        "    def GetLambda(self):\n",
        "        X = self.X  # Asegúrate de que X y Y estén definidos en tu instancia\n",
        "        Y = self.Y\n",
        "\n",
        "        K = np.dot(X, X.T) * np.dot(Y, Y.T)\n",
        "        P = matrix(K)\n",
        "        q = matrix(-np.ones((len(X), 1)))\n",
        "        G = matrix(-np.eye(len(X)))\n",
        "        h = matrix(np.zeros(len(X)))\n",
        "\n",
        "        # A debe ser una matriz con una fila y el número correcto de columnas\n",
        "        A = matrix(Y, (1, len(Y)), tc='d')  # Esto asume que Y es un array bidimensional\n",
        "        b = matrix(np.zeros(1))\n",
        "\n",
        "        sol = solvers.qp(P, q, G, h, A, b)\n",
        "        alpha = np.array(sol[\"x\"])\n",
        "        return alpha\n",
        "    \n",
        "    def GetLambdaList(self):\n",
        "        list = self.GetLambda()\n",
        "        self.lambda_list = list > 1e-10\n",
        "        return self.lambda_list\n",
        "\n",
        "    def GetW(self, X, Y):\n",
        "        self.lambda_list = self.GetLambdaList()\n",
        "        W = []\n",
        "        for j in range(X.shape[1]):\n",
        "            W.append(sum([self.lambda_list[i] * Y[i] * X[i][j] for i in range(len(self.Y))]))\n",
        "        self.w = W\n",
        "        return self.w\n",
        "\n",
        "    def GetB(self, X, W):\n",
        "        X = np.array(X)\n",
        "        W = np.array(W)\n",
        "        W_t = W.reshape(-1, 1)\n",
        "        self.b = -np.mean(np.dot(X, W_t))\n",
        "        return self.b\n",
        "\n",
        "    def Predict(self, X, W, b):\n",
        "        Y = []\n",
        "        W = np.squeeze(W)\n",
        "        for i in range(X.shape[0]):\n",
        "            X[i] = X[i].reshape(1, -1)\n",
        "            if np.dot(W, X[i]) + b >= 0:\n",
        "                Y.append(1)\n",
        "            else:\n",
        "                Y.append(-1)\n",
        "        return np.array(Y)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Test the SuperVectorMachine class\n",
        "svm = SuperVectorMachine()\n",
        "svm.X = X\n",
        "svm.Y = Y\n",
        "svm.GetLambda()\n",
        "W = svm.GetW(X, Y)\n",
        "b = svm.GetB(X, W)\n",
        "\n",
        "Y_svm = svm.Predict(X, W, b)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "\n",
        "Y_pred = svm.Predict(X_test, W, b)\n",
        "\n",
        "confussion_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.748\n",
            "[[97 23]\n",
            " [40 90]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.71      0.81      0.75       120\n",
            "           1       0.80      0.69      0.74       130\n",
            "\n",
            "    accuracy                           0.75       250\n",
            "   macro avg       0.75      0.75      0.75       250\n",
            "weighted avg       0.75      0.75      0.75       250\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Crea la figura y los ejes\n",
        "\n",
        "classes = [-1, 1]  # Clases negativa y positiva\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(confussion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title(\"Matriz de Confusión\")\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "\n",
        "# Etiqueta los valores en la matriz\n",
        "thresh = confussion_matrix.max() / 2.\n",
        "for i in range(confussion_matrix.shape[0]):\n",
        "    for j in range(confussion_matrix.shape[1]):\n",
        "        plt.text(j, i, format(confussion_matrix[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if confussion_matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.ylabel('Clase Real')\n",
        "plt.xlabel('Clase Predicha')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(accuracy_score(Y_test, Y_pred))\n",
        "print(confusion_matrix(Y_test, Y_pred))\n",
        "print(classification_report(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    # def train(self,x,y, epochs):\n",
        "    #     num_samples, num_caracteristicas = x.shape\n",
        "    #     self.numero_clases = len(np.unique(y))  \n",
        "    #     self.w = np.zeros((self.numero_clases, num_caracteristicas))\n",
        "\n",
        "    #     for i in range(epochs):\n",
        "    #        for c in range(self.numero_clases):\n",
        "    #           y_class = (y == c).astype(int)\n",
        "\n",
        "    #           s=self.S(x,self.w[c])\n",
        "    #           loss=s-y_class\n",
        "    #           gradient = np.dot(x.T, loss) / num_samples\n",
        "    #           self.w[c] -= self.alpha * gradient\n",
        "\n",
        "    # def predict(self,x):\n",
        "    #     num_samples= x.shape[0]\n",
        "    #     y_pred = np.zeros(num_samples, dtype=int)\n",
        "    #     for i in range(num_samples):\n",
        "    #          class_probs = [self.S(x[i], self.w[c]) for c in range(self.numero_clases)]\n",
        "    #          y_pred[i] = np.argmax(class_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (831,) (831,582) (831,) ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/squispeb/university/ML-Classification-p/Loader(2).ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m LinearRegression()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Fit the model to the data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39;49mTraining(X, Y)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mTesting(X)\n",
            "\u001b[1;32m/home/squispeb/university/ML-Classification-p/Loader(2).ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLossFunction(x_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m     dw, db \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDerivatives(x_train, y_train)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw \u001b[39m-\u001b[39;49m\u001b[39m=\u001b[39;49m alpha \u001b[39m*\u001b[39;49m dw\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m alpha \u001b[39m*\u001b[39m db\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/squispeb/university/ML-Classification-p/Loader%282%29.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m test_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLossFunction(x_test, y_test)\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (831,) (831,582) (831,) "
          ]
        }
      ],
      "source": [
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "model.Training(X, Y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.Testing(X)\n",
        "\n",
        "# Graph the model\n",
        "model.Graph(X, Y)\n",
        "\n",
        "# # Create a linear regression model\n",
        "# model = LinearRegression()\n",
        "\n",
        "# # Fit the model to the data\n",
        "# model.fit(X, Y)\n",
        "\n",
        "# # Make predictions\n",
        "# y_pred = model.predict(X)\n",
        "\n",
        "# # Graph the model\n",
        "# model.Graph(X, Y)\n",
        "\n",
        "\n",
        "# print(X.shape)\n",
        "# print(len(np.unique(Y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D0rpdjtWA5C4"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.utils import resample\n",
        "def selectRandomReplace(X, Y, numberOfRegisters):\n",
        "\n",
        "  bootstrap_X, bootstrap_Y = resample(X, Y, n_samples=numberOfRegisters, replace=True, random_state=None)  # Set random_state for reproducibility\n",
        "\n",
        "  return bootstrap_X, bootstrap_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fpF_yPShAEib"
      },
      "outputs": [],
      "source": [
        "def makeRandomForest(X, Y, numberOfTrees, numberOfRegisters=10):\n",
        "  T = []\n",
        "  for i in range(numberOfTrees):\n",
        "    xi_train, yi_train = selectRandomReplace(X, Y, numberOfRegisters)\n",
        "    T.append(DT())\n",
        "    T[i].fit(xi_train, yi_train)\n",
        "  return T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ick9hf5kCgv-"
      },
      "outputs": [],
      "source": [
        "Forest = makeRandomForest(X, Y, 10, 832)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HkIl75rRgB7c"
      },
      "outputs": [],
      "source": [
        "def forestPredict(x, forest):\n",
        "  classes = [t.predict(x) for t in forest]\n",
        "  unique_elements, element_counts = np.unique(classes, return_counts=True)\n",
        "  index_of_most_common = np.argmax(element_counts)\n",
        "  return unique_elements[index_of_most_common]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u0YFkrpWhWjs"
      },
      "outputs": [],
      "source": [
        "def forestPredictions(X, forest):\n",
        "  predictions = []\n",
        "  for x in X:\n",
        "    predictions.append([forestPredict(x, forest)])\n",
        "\n",
        "  return np.array(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vMhjKSiiBcF",
        "outputId": "0721ed23-464e-4274-9f92-0cca9a1ab36b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ]
        }
      ],
      "source": [
        "y_comita = forestPredictions(X_test, Forest)\n",
        "\n",
        "print(y_comita == Y_test)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
